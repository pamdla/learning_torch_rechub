# 多任务学习 (Multi-Task Learning)

## 概述

多任务学习（Multi-Task Learning，MTL）通过共享表示同时学习多个相关任务，提升模型泛化能力。在推荐系统中常用于同时优化CTR、CVR等多个目标。

---

## 模型对比总表

| 模型 | 原理 | 优点 | 缺点 | 复杂度 | 负迁移 | 参数量 | 选型建议 |
|:----:|------|------|------|:------:|:------:|:------:|----------|
| **SharedBottom** | 共享底层+独立塔 | 结构简单、推理快、易部署 | 任务冲突时负迁移严重 | ⭐ | ❌ | 小 | 资源有限/任务强相关首选 |
| **ESMM** | 全空间CTR/CVR级联 | 解决样本选择偏差 | 仅适用级联任务 | ⭐ | ❌ | 小 | CTR+CVR联合优化首选 |
| **MMoE** | 多专家+门控动态组合 | 灵活解耦，自动平衡共享/独立 | 门控增加复杂度 | ⭐⭐ | ✅ | 中 | 通用多任务/任务有冲突 |
| **PLE** | 分层专家(专享+共享)渐进提取 | 有效缓解负迁移，表达能力强 | 参数量大、训练慢 | ⭐⭐⭐ | ✅✅ | 大 | 大规模工业/严重负迁移 |
| **AITM** | 注意力自适应传递任务信息 | 建模任务依赖，可解释性好 | 需设计注意力，训练较难 | ⭐⭐ | ✅ | 中 | 用户行为序列/任务依赖 |

---

## 快速选型

```
判断维度 → 推荐模型

任务强相关 ──────→ SharedBottom
CTR+CVR级联 ────→ ESMM
任务有冲突 ──────→ MMoE ─→ 冲突严重 → PLE
序列依赖 ────────→ AITM
```

| 判断维度 | 条件 | 推荐模型 |
|----------|------|----------|
| **任务关系** | 强相关 | SharedBottom |
| | 级联(CTR→CVR) | ESMM |
| | 有冲突 | MMoE / PLE |
| | 序列依赖 | AITM |
| **资源** | 有限 | SharedBottom / ESMM |
| | 充足 | MMoE / PLE / AITM |
| **数据量** | 小 | SharedBottom |
| | 大 | PLE / AITM |


## 心得总结

刚深挖 MMoE 模型，觉得它用多专家网络 + 门控动态路由太聪明了！共享专家学通用模式，任务专家挖特异需求，完美解决 B 端“是否进货”和“进多少”的梯度冲突。torch-rechub 上手快，但 Embedding 索引越界和标签格式坑不少，数据校验和特征工程还是得用心～

---
## 运行示例

### 依赖安装
```bash
pip install torch_rechub numpy pandas torch joblib
```

### 运行
```bash
python demo.py
```

### 输出
- 训练完成后显示 Task 1/2 AUC
- 生成 `mmoe.onnx` ONNX模型
- 生成 `predictions.csv` 预测结果

### 关键参数调优
| 参数 | 当前值 | 调优建议 |
|------|--------|----------|
| n_samples | 1000 | 增至10000+ |
| n_expert | 8 | 增至16 |
| expert_dims | [256,128] | 增至[512,256] |
| lr | 0.001 | 降至0.0005 |
